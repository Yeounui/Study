---
title: "Project 2: Linear Regression"
author:
  - Jongbum Won (01815150)
output: html_document
date: '2022-04-21'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggplot2)
```

# **1. Statistical Analysis**
### (a) Explanatory analysis
```{r}
penguins <- read.csv("penguins.csv", header=TRUE)
penguins = penguins[complete.cases(penguins),]
attach(penguins)
```

Load `penguins` dataset and attach. Remove data points with at least one NA value.

```{r}
ggplot(penguins, 
       mapping=aes(bill_length_mm, body_mass_g, color=species, shape=species)) + 
  geom_smooth(method = "lm", level = 0.95 , formula = y ~ x, color='black', size = 0.7) +
  geom_smooth(method = "loess", level = 0.95 , se = FALSE, linetype=6, formula = y ~ x, size=0.5, color='black') +
  ggtitle('Body Mass (g) vs Bill Length (mm)') + geom_point()

ggplot(penguins, 
       mapping=aes(bill_depth_mm, body_mass_g, color=species, shape=species)) + 
  geom_smooth(method = "lm", level = 0.95 , formula = y ~ x, color='black', size = 0.7) +
  geom_smooth(method = "loess", level = 0.95 , se = FALSE, linetype=6, formula = y ~ x, size=0.5, color='black') +
  ggtitle('Body Mass (g) vs Bill Depth (mm)') + geom_point()

ggplot(penguins, 
       mapping=aes(flipper_length_mm, body_mass_g, color=species, shape=species)) + 
  geom_smooth(method = "lm", level = 0.95 , formula = y ~ x, color='black', size = 0.7) +
  geom_smooth(method = "loess", level = 0.95 , se = FALSE, linetype=6, formula = y ~ x, size=0.5, color='black') +
  ggtitle('Body Mass (g) vs Flipper Length (mm)') + geom_point()

```

Check if there is linear relatioship three continuous features (`bill_length_mm`, `bill_depth_mm`, and `filpper_length_mm`) and weight of an individual penguin (`body_mass_g`).  
Draw best fit linear regression lines (solid) together with loess (locally weighted scatterplot smoothing) curves (dotted) on the scatter plot for each species.  
The curves quite approximate well corresponding lines, except for ends of lines with low number of observations.  
Thus, from the graphs, we can conclude that it is reasonable to assume that there are linear relationships between `bill_length_mm` and `body_mass_g`, `bill_depth_mm` and `body_mass_g`, and `filpper_length_mm` and`body_mass_g`.  

Q Lowess vs loess? 

### (b) Building optimal regression model

```{r}
model1 <- lm(body_mass_g ~ bill_length_mm) 
summary(model1)
```
```{r}
model2 <- lm(body_mass_g ~ bill_depth_mm) 
summary(model2)
```

```{r}
model3 <- lm(body_mass_g ~ flipper_length_mm) 
summary(model3)
```
For the first round of the forward model building, it seems all each predictor is significant (for estimation on population parameter $\beta$), since p-values are way smaller than 5% significance level. So, we choose with the most significant predictor among them and it is `fliper_length_mm` because its absolute t-value is highest (i.e., p-value is lowest).

Continue with model3, adding other predictors one by one.

```{r}
model4 <- lm(body_mass_g ~ flipper_length_mm + bill_length_mm)
summary(model4)
```

```{r}
model5 <- lm(body_mass_g ~ flipper_length_mm + bill_depth_mm)
summary(model5)
```

As adding `bill_length_mm` and `bill_depth_mm` one by one on the model, their p-values are not lower than the 5% significance level.  
Adding those predictors do not have a significant effect, and therefore keep with model3 with only `filpper_length_mm`.  
Now look at the effect of adding higher order terms of it.  

```{r}
model6 <- lm(body_mass_g ~ flipper_length_mm + I(flipper_length_mm^2))
summary(model6)
```
```{r}
model7 <- lm(body_mass_g ~ flipper_length_mm + I(flipper_length_mm^2) + I(flipper_length_mm^3))
summary(model7)
```

Both adding second and third order terms have significant effect on the model,    
as their p-values are lower than 5% significance level (also adding one at a time in order).  


```{r}
model8 <- lm(body_mass_g ~ flipper_length_mm + I(flipper_length_mm^2) + I(flipper_length_mm^3)+ I(flipper_length_mm^4))
summary(model8)
```
However, adding more higher order term (fourth order) is not significant, and even other terms become insignificant. 
So determine predictors with first, second, and third order of `flipper_length_mm` as our final model for part (b).  

```{r}
finalmodel_b <- model7
par(mfrow = c(2, 2))
plot(finalmodel_b)
```  

Check for assumptions:  
- linearity -> No pattern: linear
- Normality -> QQ Plot: normal
- Homeoscadasticity -> No pattern: okay
- Independency -> ?


```{r}
model_d1 <- lm(body_mass_g ~ flipper_length_mm + I(flipper_length_mm^2) + I(flipper_length_mm^3) + factor(species))
summary(model_d1)
anova(finalmodel_b, model_d1)

model_d2 <- lm(body_mass_g ~ flipper_length_mm + I(flipper_length_mm^2) + I(flipper_length_mm^3) + factor(island))
anova(finalmodel_b, model_d2)

model_d3 <- lm(body_mass_g ~ flipper_length_mm + I(flipper_length_mm^2) + I(flipper_length_mm^3) + factor(sex))
anova(finalmodel_b, model_d3)
```

H0: Model to which the categorical predictor added is same with previous model in terms of explaining data  
    
Adding `sex` variable as a predictor has the most significant effect on the finalmodel_b than the other categorical variables,  
since the p-value of ANOVA test is the smallest.  
Therefore, select model_d3 as our model and try addition of remaining terms on it.

```{r}
model_d4 <- lm(body_mass_g ~ flipper_length_mm + I(flipper_length_mm^2) + I(flipper_length_mm^3) + factor(sex) + factor(species))
anova(model_d3, model_d4)

model_d5 <- lm(body_mass_g ~ flipper_length_mm + I(flipper_length_mm^2) + I(flipper_length_mm^3) + factor(sex) + factor(island))
anova(model_d3, model_d5)
```
Adding `species` has more significant effect, according to lower p-value again.
Select `model_d4` and finally try to use all 3 terms.



```{r}
model_d6 <- lm(body_mass_g ~ flipper_length_mm + I(flipper_length_mm^2) + I(flipper_length_mm^3) + factor(sex) + factor(species) + factor(island)) 
anova(model_d4, model_d6)
```

Adding `island` has no significant effect on our model.  
In conclusion, adding two terms 
Thus, select `model_d4` as our final model for the part (d).

```{r}
finalmodel_d <- model_d4
par(mfrow = c(2, 2))
plot(finalmodel_d)
```

Fitted values become more equally distributed than model without categorical variables.
Normality becomes better than before even at the two ending sites.
(Others? seems better, but not sure...)

```{r}
predict(finalmodel_d, newdata = data.frame(flipper_length_mm = 188, sex = 'female', species = 'Adelie'), interval = "confidence", level = 0.95)
predict(finalmodel_d, data= penguins)
```

```{r}
fit <- predict(finalmodel_d, data= penguins)
obs <- penguins$body_mass_g

plot(fit, obs)
abline(lsfit(fit, obs), lty = 1)
lines(lowess(fit, obs), lty = 2)
```


